<Html>

<Head>
<BODY BGCOLOR="#FFFFFF" link=blue alink=green vlink=red>
<Title>
CSCI/ARTI 8950 Machine Learning
</Title>

<Link Rev="made" Href="mailto:krasheed@cs.rutgers.edu">

</Head>

<Body>

<H1>CSCI/ARTI 8950 Machine Learning</H1>

Spring 2008: Tuesdays and Thursdays 3:30pm - 4:45pm & Wednesdays
3:35pm - 4:25pm, Boyd GSRC 208</BR>

</BR>

<A HREF="http://www.cs.uga.edu/~khaled/">Instructor: Prof. Khaled
Rasheed</A> </BR>
Telephone: (706)542-3444</BR> 
Office Hours: Tuesday: 1-2:30pm and Wednesday: 4:35-6:00pm or by email
appointment</BR>
Office Location: Room 219B, Boyd GSRC</BR> 
Email: khaled@cs.uga.edu</BR>
</BR>
<Hr>

<H2>Objectives:</H2> 

Machine learning is a sub-field of artificial intelligence which is
concerned with computer programs that can automatically improve their
capabilities and/or performance by acquiring (learning) experience.
The main objectives of this course are to provide students with an
in-depth introduction to machine learning theory and methods
and an exploration of research problems in machine learning and its
applications which may lead to work on a project or a dissertation.

The course is intended primarily for computer science and artificial
intelligence graduate students. Graduate students from other
departments who have a strong interest and sufficient experience in
artificial intelligence may also find the course interesting.

<H2>Recommended Background:</H2> 

CSCI/PHIL 4550/6550 Artificial Intelligence or CSCI 4560/6560
Evolutionary Computation (or permission of the instructor).
Familiarity with basic computer algorithms and data structures and at
least one high level programming language.

<H2>Topics to be Covered:</H2> 

<li>Part I: Machine learning techniques: Selected from inductive learning,
decision trees, neural network approaches, evolutionary computation
approaches and classifier systems, reinforcement learning, statistical
and Bayesian learning, instance-based learning, explanation-based
learning and computational learning theory.

<li>Part II: Machine learning applications: Selected from data mining,
biomedical modelling, medical diagnosis, text classification, pattern
recognition and/or other contemporary applications.


<H2>Expected Work:</H2> 

Reading; assignments (some include programming and/or running existing
programs); midterm; final and term project and paper.  (Unless
otherwise announced by the instructor: all assignments and all exams
must be done entirely on your own.)

<H2>Academic Honesty and Integrity:</H2> 

All academic work must meet the standards contained in <A
HREF="http://www.uga.edu/honesty/ahpd/culture_honesty.htm">
"A Culture of Honesty."</A> Students are responsible for informing
themselves about those standards before performing any academic
work. The penalties for academic dishonesty are severe and ignorance
is not an acceptable defense.

<H2>Grading Policy:</H2> 

<li>Assignments: 30% (Programs, homeworks, attendance, paper presentation)
<li>Midterm Examination: 20%  
<li>Final Examination: 20% 
<li>Term Project: 30% (includes term paper and presentation)
<br>

Students may work on their term projects in groups of up to
<strong>three</strong> students each. The above distribution is only
tentative and may change later. The instructor will announce any
changes.

<H2>Assignment Submission Policy</H2> 

Assignments must be turned in by the assigned deadline. Late
assignments will not be accepted. Rare exceptions may be made by the
instructor only under extenuating circumstances and in accordance with
the university policies.

<H2>Course Home-page</H2> 

A variety of materials will be made available on the ML Class
Home-page at <A HREF="http://www.cs.uga.edu/~khaled/MLcourse/">
http://www.cs.uga.edu/~khaled/MLcourse/</a>, including handouts,
lecture notes and assignments. Announcements may be posted between
class meetings.  You are responsible for being aware of whatever
information is posted there.

<H2>Lecture Notes</H2>

Copies of <strong>some</strong> of Dr. Rasheed's lecture notes will be
available at the bottom of the class home page. Not all the lectures
will have electronic notes though and the students should be prepared
to take notes inside the lecture at any time.

<H2>Textbook in Bookstore</H2> 

<li> "Machine Learning", Tom Mitchell.  McGraw-Hill, 1997. (Required.) 

<H2>Additional Books</H2> 

<li> "Data Mining: Practical Machine Learning Tools and Techniques
(2nd edition)", Ian Witten & Eibe Frank. Morgan Kaufmann, 2005.

<li> "Evolutionary Computation : Towards a New Philosophy of Machine
Intelligence", David Fogel. IEEE press, 1999.


<H2>Web Resources</H2> 

<li> <A
HREF="http://home.earthlink.net/~dwaha/research/machine-learning.html">
David Aha's Machine Learning Resources</a>

<li> <A HREF="http://archive.ics.uci.edu/ml/">
University of California at Irvine ML Repository</a>

<li> <A HREF="http://www.cs.waikato.ac.nz/~ml">
The WEKA Machine Learning Project</a>

<H2>Announcements:</H2>

<li>4-23-2008: Your scores so far are posted <A
HREF="2008_CSCI_ARTI_8950.htm">HERE</A>. Please make sure that your
homework scores are properly recorded.

<li>4-23-2008: The final exam will be on Tuesday, May 6th from 3:30
pm to 6:30 pm in the same room where the class met during the
semester. The exam will be open book and notes and will cover all the
material covered in the course including all handouts. You should
bring your lecture notes, handouts and any books or notes you
anticipate using in the exam. The use of cell phones, laptops or any
computers or communication devices will not be allowed in the
exam. One paper from among those presented by students in class will
be selected at random to become the subject of one question in the
final. Copies of that paper will be made for all of you and therefore
you need not bring copies of any or all of those papers to the exam.

<li>4-23-2008: The course project reports are due at the final
exam. For the project report format, please write it as a conference
paper of about 8 two-column pages or 12 single-column pages (there is
no restriction on size though). You should include an introduction, a
mention of related work, a description of your experiments and results
and a conclusion. In the introduction or elsewhere in the paper you
should describe the domain that you applied your ML technique(s) to,
in enough detail for the reader to appreciate the significance and
difficulty of the problem. Please bring a hard copy to the exam and
include your email addresses as well as the URLs of any
demo/supporting web pages. There is a slight chance that I might
contact you soon after the submission deadline (within 48 hours)
requesting codes, clarifications or more data. Thus it will be helpful
to include the emails of all the group members lest one or more are
going to leave town immediately after the submission.

<li> [2-3-2008] Cesar has kindly prepared a power point presentation
about Weka that you can find <A HREF="WEKA.pps">HERE</A>. This has
many more slides than the ones he showed in class and provides a
complete tutorial.

<H2>Papers</H2>

<li> "Mining Distance Based Outliers in Near Linear Time with
Randomization and a Simple Pruning Rule" Bay and Schwabacher,
2003. [David Luper][4-2]{<A
HREF="http://www.isle.org/~sbay/papers/outliers.kdd03.pdf">download</A>}

<li> "Link Mining Applications: Progress and Challenges" Ted Senator,
2005. [Yong Wu][4-2]{<A
HREF="http://www.sigkdd.org/explorations/issues/7-2-2005-12/10-Senator.pdf">download</A>}

<li> "Facial expression recognition from video sequences: temporal and
static modeling" Cohen et al., 2003. [Devangana Kar][4-3] {<A
HREF="http://coblitz.codeen.org:3125/citeseer.ist.psu.edu/cache/papers/cs/31365/http:zSzzSzcarol.science.uva.nlzSz~nicuzSzpublicationszSzCVIU-Ira.pdf/cohen03facial.pdf">download</A>}

<li> "An introduction to variable and feature selection" Guyon and
Ellisseeff, 2003. [Yingfeng Wang][4-8]{<A
HREF="http://www.eecs.wsu.edu/~holder/courses/cse6363/spr04/present/Guyon03.pdf">download</A>}

<li> "Online Feature Selection for Pixel Classication" Glocer et al.,
2005. [Anousha Mesbah][4-9] {<A
HREF="http://www.machinelearning.org/proceedings/icml2005/papers/032_Online_GlocerEtAl.pdf">download</A>}

<li> "Fusion of LDA and PCA for Face Recognition" Marcialis and Roli,
 2005.  [Zhibin Huang][4-9] {<A
 HREF="http://www.diee.unica.it/informatica/en/publications/papers-prag/Bio-Conference-05.pdf">download</A>}

<li> "Modern Information Retrieval: A Brief Overview" Amit Singhal,
2001.  [Dong Zhang][4-9]{<A
HREF="http://pages.cs.wisc.edu/~anhai/courses/784-sp08-anhai/ir_overview.pdf">download</A>}

<li> "A Machine Learning Approach to Keystroke Dynamics Based User
Authentication" Revett et al., 2007. [Kushel Bellipady][4-10]{<A
HREF="http://repositorium.sdum.uminho.pt/bitstream/1822/6388/1/f191031146728125.pdf">download</A>}

<li> "Face Recognition using Eigenfaces and Neural Networks" Rizon et
al., 2006. [Shiva Sandeep][4-15]{<A
HREF="http://www.scipub.org/fulltext/ajas/ajas361872-1875.pdf">download</A>}

<li> "Informed operators: Speeding up genetic-algorithm-based design optimization using reduced models" Rasheed and Hirsh, 2000. [Meng Meng][4-15]{<A
HREF="./RW164.pdf">download</A>}

<li> "Learning to Detect and Classify Malicious Executables in the
Wild" Kolter and Maloof, 2006. [Eric Drucker][4-15] {<A
HREF="http://jmlr.csail.mit.edu/papers/volume7/kolter06a/kolter06a.pdf">download</A>}

<li> "A machine learning approach to POS tagging" Marquiz et al.,
2000. [Jiayun Han][4-16]{<A HREF="
http://www.springerlink.com/content/p8w6123l75766757/">download</A>}

<li> "YALE: Rapid Prototyping for Complex Data Mining Tasks" Mierswa
et al., 2006. [Muthukumaran][4-16] {<A
HREF="http://citeseer.ist.psu.edu/mierswa06yale.html">download</A>}

<li> "Bayesian Optimization Algorithm, Population Sizing, and Time to
Convergence" Pelikan et al., 2000.[Karan Sharma][4-16] {<A
HREF="https://e-reports-ext.llnl.gov/pdf/238344.pdf">download</A>}

<li> "New Lower Bounds for the Snake-In-The-Box Problem: Using
Evolutionary Techniques to Hunt for Snakes" Casella and Potter,
2004. [Kartheek][4-17]{<A
HREF="http://www.cs.uga.edu/~potter/CompIntell/SnakePaper94.pdf">download</A>}

<li> "Learning user interaction models for predicting web search
result preferences" Agichtein et al., 2006. [Amir H. Asiaee][4-17]{<A
HREF="http://www.mathcs.emory.edu/~eugene/papers/sigir2006preferences.pdf">download</A>}

<li> "Learning User Preferences for Sets of Objects" Marie des Jardins
et al.,2006. [Bijaya Rath][4-17]{<A
HREF="http://www.icml2006.org/icml_documents/camera-ready/035_Learning_User_Prefer.pdf">download</A>}

<H2>Assignments:</H2> 

<li>
<A HREF="homework1.pdf">Assignment 1</A>
<li>
<A HREF="homework2.pdf">Assignment 2</A>
<li>
<A HREF="homework3.pdf">Assignment 3</A>
<li>
<A HREF="homework4.pdf">Assignment 4</A>
<li>
<A HREF="homework5.pdf">Assignment 5</A>
<li>
<A HREF="homework6.pdf">Assignment 6</A>
<li>
<A HREF="homework7.pdf">Assignment 7</A>

<H2>Lecture Notes:</H2> 
<li>
<A HREF="ML.pdf">Introduction </A>
<li>
<A HREF="ML-C1.pdf">Chapter 1</A>
<li>
<A HREF="ML-C2.pdf">Chapter 2</A>
<li>
<A HREF="ML-C3.pdf">Chapter 3</A>
<li>
<A HREF="ML-C4.pdf">Chapter 4</A>
<li>
<A HREF="ML-C5.pdf">Chapter 5</A>
<li>
<A HREF="ML-C6.pdf">Chapter 6</A>
<li>
<A HREF="ML-C8.pdf">Chapter 8</A>
<li>
<A HREF="EC.pdf">Evolutionary Computation</A>
<li>
<A HREF="ML-C7.pdf">Chapter 7</A>


<Hr>

<strong>The course syllabus is a general plan for the course;
deviations announced to the class by the instructor may be
necessary.</strong><BR>

<P>

Last modified: April 23, 2008.
<ADDRESS>
<A Href="http://www.cs.uga.edu/~khaled" Name="signature">Khaled Rasheed</A
>
(<A Href="mailto:khaled@cs.uga.edu">khaled[at]cs.uga.edu</A>)

</ADDRESS>

</Body>

</Html>